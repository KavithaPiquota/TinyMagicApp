{
  "chatgpt": {
    "model": "gpt-4-turbo",
    "temperature": 0.7,
    "maxTokens": 4096,
    "topP": 1
  },
  "openai": {
    "model": "gpt-4",
    "temperature": 0.7,
    "maxTokens": 8192,
    "topP": 1
  },
  "groq": {
    "model": "llama-3.3-70b-versatile",
    "temperature": 0.7,
    "maxTokens": 31980,
    "topP": 1
  },
  "gemini": {
    "model": "gemini-pro",
    "temperature": 0.8,
    "maxTokens": 2048,
    "topP": 0.9
  },
  "default": {
    "model": "llama-3.3-70b-versatile",
    "temperature": 0.7,
    "maxTokens": 31980,
    "topP": 1
  }
}
